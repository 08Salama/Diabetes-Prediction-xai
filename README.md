📊 Enhancing Diabetes Prediction Models with Machine Learning & Explainable AI Techniques
🎓 MSc Data Analytics and Technology — University of Bolton
Author: Syeda Salama Juweria Quadri
Supervisor: Mr Aamir Abbas
Module Tutor: Dr Thaier Hamid

🧠 Project Overview
This project aims to enhance diabetes prediction using various machine learning algorithms and explainable AI (XAI) techniques. The goal is to build accurate and interpretable models that can assist healthcare professionals in early diagnosis and decision-making.

🛠️ Technologies Used
Programming Language: R
Libraries: caret, randomForest, ggplot2, dplyr, lubridate, tseries, ggmap
Explainable AI Tools: SHAP (Shapley Additive Explanations), LIME (Local Interpretable Model-Agnostic Explanations)
📈 Machine Learning Models
Logistic Regression
Decision Tree
Random Forest
Gradient Boosting Machine (GBM)
Support Vector Machine (SVM)
K-Nearest Neighbors (KNN)
📊 Performance Metrics
Accuracy
Precision
Recall
F1 Score
AUC-ROC
Confusion Matrix
GBM achieved the highest accuracy (94.4%) and AUC (96%), followed closely by Random Forest.

🔍 Explainable AI
SHAP was used to identify feature importance across the dataset.
LIME provided local explanations for individual predictions.
Key features influencing diabetes prediction included: HbA1c, FastingBloodSugar, Hypertension, and FrequentUrination.
📂 How to Run the Code
Clone the repository:

Open myfinal.R in RStudio.
Ensure required libraries are installed.
Run the script to load data, preprocess, train models, and generate visualizations.
📌 Dataset
Source: Kaggle
Contains 46 features and 1879 anonymized patient records.
📚 Research Contribution
This project demonstrates how combining machine learning with XAI can improve transparency and trust in predictive healthcare models. It provides actionable insights for early diabetes diagnosis and supports clinical decision-making.

📬 Contact
For questions or collaboration: Email  : juweria14331@gmail.com

LinkedIn : www.linkedin.com/in/syeda-salama-juweria-quadri-a198a4264
